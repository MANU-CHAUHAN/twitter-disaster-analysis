{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone_BERT_LARGE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOUmYOGOJdJBz47qtDpbRlg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MANU-CHAUHAN/twitter-disaster-analysis/blob/main/Capstone_BERT_LARGE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TbphG-ktU7J"
      },
      "source": [
        "!pip install transformers -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asa_lnWQr6Rj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f53d4bd2-4347-4ef7-e3a4-4127f9cb59f5"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from transformers import AutoTokenizer, TFBertModel\n",
        "import numpy as np\n",
        "from sklearn import model_selection\n",
        "URL = 'https://drive.google.com/file/d/1fLX0XxkbSXatVevvndyqkBDxNOgWcUHP/view?usp=sharing'\n",
        "path = 'https://drive.google.com/uc?export=download&id='+URL.split('/')[-2]\n",
        "#df = pd.read_pickle(path)\n",
        "df = pd.read_csv(path)\n",
        "df.head()\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-large-uncased')\n",
        "bert = TFBertModel.from_pretrained('bert-large-uncased')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeLsqEJPsXB0"
      },
      "source": [
        "df_c = df.copy()\n",
        "df_c=df_c.drop(columns=['keyword','id', 'location'])\n",
        "df_c=df_c.dropna()"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuW0EH9ssaI2"
      },
      "source": [
        "df_c.text=df_c.text.apply(lambda x:x.lower() )\n",
        "#removing square brackets\n",
        "df_c.text=df_c.text.apply(lambda x:re.sub('\\[.*?\\]', '', x) )\n",
        "df_c.text=df_c.text.apply(lambda x:re.sub('<.*?>+', '', x) )\n",
        "#removing hyperlink\n",
        "df_c.text=df_c.text.apply(lambda x:re.sub('https?://\\S+|www\\.\\S+', '', x) )\n",
        "#removing puncuation\n",
        "df_c.text=df_c.text.apply(lambda x:re.sub('[%s]' % re.escape(string.punctuation), '', x) )\n",
        "df_c.text=df_c.text.apply(lambda x:re.sub('\\n' , '', x) )\n",
        "#remove words containing numbers\n",
        "df_c.text=df_c.text.apply(lambda x:re.sub('\\w*\\d\\w*' , '', x) )\n",
        "\n",
        "#df_c.iloc[:-10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWqgWIuq3NOM"
      },
      "source": [
        "\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPilWXZU00fI"
      },
      "source": [
        "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(df_c['text'],df_c['target'],test_size=0.3)"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KBBIiiVIgKI",
        "outputId": "415fe366-1301-4d87-e143-a6a6966a5cb8"
      },
      "source": [
        "Train_X"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8083                          mary coming to troy rescue  \n",
              "6369     sinjar massacre yazidis blast lack of action o...\n",
              "7311     nuclear reactor railguns would be a great way ...\n",
              "526      one direction is my pick for  fan army directi...\n",
              "3056     ûïlolgop  cases of voter fraud a year we need...\n",
              "                               ...                        \n",
              "10273    kasiakosek the drive sucks in my case because ...\n",
              "2116     iphone twist ultimate preparedness library  pr...\n",
              "7050                  the ol meltdown victory for the mets\n",
              "8280     georgous what alternatives legal alternatives ...\n",
              "7982     the latest more homes razed by northern califo...\n",
              "Name: text, Length: 5329, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRIwgmXz1AXw"
      },
      "source": [
        " #train\n",
        " x_1= tokenizer(\n",
        "    text=Train_X.to_list(),\n",
        "    add_special_tokens=False, #only in this case\n",
        "    max_length=41, #not sure about this\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        " y_1=Train_Y.to_numpy()\n",
        "# test\n",
        " x_2= tokenizer(\n",
        "    text=Test_X.to_list(),\n",
        "    add_special_tokens=False, #only in this case\n",
        "    max_length=41,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        " y_2=Test_Y.to_numpy()"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZKRlh_MJ6UM",
        "outputId": "8a01a787-1922-4aee-c45a-1055b83c6d93"
      },
      "source": [
        "x_1"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(5329, 41), dtype=int32, numpy=\n",
              "array([[ 2005,  2216,  2040, ...,     0,     0,     0],\n",
              "       [ 3422,  2023,  3199, ...,     0,     0,     0],\n",
              "       [ 2525,  6634,  6834, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [ 1045,  2245,  1996, ...,     0,     0,     0],\n",
              "       [ 6608,  1037,  9964, ...,     0,     0,     0],\n",
              "       [11652,     0,     0, ...,     0,     0,     0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(5329, 41), dtype=int32, numpy=\n",
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 0, 0, ..., 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUKsrNvAsc0W"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "max_len = 41 \n",
        "input_ids = keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
        "input_mask = keras.Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
        "embeddings = bert(input_ids,attention_mask = input_mask)[1]\n",
        "out = tf.keras.layers.Dropout(0.1)(embeddings)\n",
        "out = keras.layers.Dense(128, activation='relu')(out)\n",
        "out = tf.keras.layers.Dropout(0.1)(out)\n",
        "out = keras.layers.Dense(32,activation = 'relu')(out)\n",
        "y = keras.layers.Dense(1,activation = 'sigmoid')(out)\n",
        "    \n",
        "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
        "model.layers[2].trainable = True"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duUGTKLhNsWD"
      },
      "source": [
        "optimizer = keras.optimizers.Adam(\n",
        "    learning_rate=6e-06, # this learning rate is taken from huggingface website \n",
        "    epsilon=1e-08,\n",
        "    decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss = keras.losses.BinaryCrossentropy(from_logits = True)\n",
        "metric = keras.metrics.BinaryAccuracy('accuracy'),\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss, \n",
        "    metrics = metric)"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfJWb67ENst9",
        "outputId": "4d59251e-6584-463b-ea83-2168b53da7c0"
      },
      "source": [
        "train_history = model.fit(\n",
        "    x ={'input_ids':x_1['input_ids'],'attention_mask':x_1['attention_mask']} ,\n",
        "    y = y_1, epochs=1, batch_size=32\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 12/167 [=>............................] - ETA: 2:04:33 - loss: 0.7327 - accuracy: 0.5312"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "w89ramtVRH7L",
        "outputId": "e3eb91b4-50cd-4614-9202-c3af6f8e9cc3"
      },
      "source": [
        "predicted = model.predict({'input_ids':x_2['input_ids'],'attention_mask':x_2['attention_mask']})\n",
        "y_predicted = np.where(predicted>0.5,1,0)\n",
        "y_predictedd = y_predicted.reshape((1,3263))[0]"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-128-562f07e3920e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_predictedd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3263\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model_1\" is incompatible with the layer: expected shape=(None, 73), found shape=(None, 40)\n"
          ]
        }
      ]
    }
  ]
}